{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153711,
     "status": "ok",
     "timestamp": 1751531482506,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "eVkvX0hQ0YcU",
    "outputId": "5f776038-ef87-4b87-ec5e-d74bb2f58764"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1751531483193,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "qNg_PXq30er1",
    "outputId": "439c36c8-ad6c-406e-b909-fb6d56658817"
   },
   "outputs": [],
   "source": [
    "# Path to the folder containing the images you want to analyze\n",
    "IMAGE_FOLDER_PATH = \"Data/images/\"\n",
    "\n",
    "IMAGE_SPEC = \"Obsidian_old\"\n",
    "\n",
    "IMAGE_PATH = os.path.join(IMAGE_FOLDER_PATH, IMAGE_SPEC)\n",
    "# Path to the trained model file (.pth) saved from the training notebook\n",
    "MODEL_FOLDER_PATH = \"Data/segmentation_models/\"\n",
    "\n",
    "MODEL_SPEC = \"obsidian_f1a05b05.pth\"\n",
    "\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER_PATH, MODEL_SPEC)\n",
    "\n",
    "# Path to the directory where results  will be saved\n",
    "OUTPUT_PATH = \"Data/inference_results\"\n",
    "\n",
    "# ---  MODEL PARAMETERS (These MUST match the model you are loading) ---\n",
    "MODEL_ARC = \"Unet\"\n",
    "ENCODER = \"resnet34\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "# --- 3. PREPROCESSING PARAMETERS (These MUST match how the model was trained) ---\n",
    "# Image dimensions the model was trained on\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_WIDTH = 1024\n",
    "# Number of channels in the *source* images (1 for grayscale, 3 for color).\n",
    "INPUT_CHANNELS_CONFIG = 3\n",
    "\n",
    "# --- 4. INFERENCE PARAMETERS ---\n",
    "# Probability threshold to convert model output to a binary mask\n",
    "PREDICTION_THRESHOLD = 0.5\n",
    "# Set to None if unknown.\n",
    "PIXEL_RESOLUTION_UM_PER_PX = None\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "if not os.path.isdir(IMAGE_PATH):\n",
    "    raise FileNotFoundError(f\"ERROR: Image folder not found at '{IMAGE_PATH}'\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"ERROR: Model file not found at '{MODEL_PATH}'\")\n",
    "\n",
    "print(f\"Configuration Loaded:\")\n",
    "print(f\"  Image Folder: {IMAGE_PATH}\")\n",
    "print(f\"  Model Path: {MODEL_PATH}\")\n",
    "print(f\"  Output Directory: {OUTPUT_PATH}\")\n",
    "print(f\"  Using Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1751531483252,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "VUoJUmHb0mqz"
   },
   "outputs": [],
   "source": [
    "def get_inference_augs(height, width):\n",
    "    \"\"\"Defines transformations for inference (resizing).\"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(height, width, interpolation=cv2.INTER_LINEAR, always_apply=True),\n",
    "    ])\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Combines model-specific normalization with tensor conversion.\"\"\"\n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225,
     "referenced_widgets": [
      "c0cc94574bc44acf91280adabdfae085",
      "c23a9f66d68a41a28d1fcaee6e8baf7f",
      "fcd950f2a5464b5092117e01c839a118",
      "e13a8e6f94cc49b4a061ce3e0b4a5952",
      "9908b8d198a44a809db7d44240af57d7",
      "3a3e3a9386bd42edbf95b56cd180ac39",
      "f3bd213cbdaa4363a44a3fe8acd2a008",
      "42ed84645b494c939b264233f480776a",
      "c331c692b29c49db9f8f32c01030ff0e",
      "14c60120f92242fba7efec769301e649",
      "ee127e37229c4c7386ede884d017759b"
     ]
    },
    "executionInfo": {
     "elapsed": 5813,
     "status": "ok",
     "timestamp": 1751531489061,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "O8ioMoQV0n-Q",
    "outputId": "5726b8dd-7135-4b4d-ae52-01d36244bacc"
   },
   "outputs": [],
   "source": [
    "print(\"Loading trained model...\")\n",
    "\n",
    "try:\n",
    "    # Instantiate the model with the same architecture as during training\n",
    "    inference_model = smp.create_model(\n",
    "        arch=MODEL_ARC,\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=None,\n",
    "        in_channels=INPUT_CHANNELS_CONFIG,\n",
    "        classes=1,\n",
    "        activation=None, \n",
    "    )\n",
    "    inference_model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    inference_model.to(DEVICE)\n",
    "    inference_model.eval()\n",
    "    print(\"Model loaded successfully and set to evaluation mode.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating or loading model: {e}\")\n",
    "    print(\"Please ensure MODEL_ARC and ENCODER parameters in Cell 2 are correct.\")\n",
    "    raise e\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "print(\"Preprocessing function loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "2e16b52f4a0d44a2bf5e69135bad222c",
      "faf451618b494071afbe46a198bca2de",
      "9f7b1c43bdb44a65b0f7595dde324762",
      "f711f124e1d54cc0981f0bf9f56b7a82",
      "19708ff18d4545ef847724e9c41b0755",
      "69310da730154458ad1197397d2589f8",
      "a4877cc62c3b40a9a69912ba239f1b7f",
      "2337a372a3784adfa54f7e6af944b067",
      "e3ace6462d904ddab727fb976a0a2f3f",
      "1dd3f54a68684034b5f11392c7751dd5",
      "60edd04712624697b9de164c95120220"
     ]
    },
    "executionInfo": {
     "elapsed": 421372,
     "status": "ok",
     "timestamp": 1751531920762,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "Sy9Ag4Ow0p6y",
    "outputId": "a20d1ad0-2d3d-44ab-b7bf-3adcb9de28ba"
   },
   "outputs": [],
   "source": [
    "all_detected_properties = []\n",
    "visualization_samples = []\n",
    "NUM_SAMPLES_TO_VISUALIZE = 3 \n",
    "\n",
    "# Get preprocessing pipelines\n",
    "inference_augs_pipeline = get_inference_augs(IMG_HEIGHT, IMG_WIDTH)\n",
    "preprocessing_pipeline = get_preprocessing(preprocessing_fn)\n",
    "\n",
    "# Find all images in the folder\n",
    "image_paths = glob.glob(os.path.join(IMAGE_PATH, '*'))\n",
    "image_paths = [p for p in image_paths if p.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))]\n",
    "\n",
    "if not image_paths:\n",
    "    print(f\"Error: No images found in '{IMAGE_PATH}'.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(image_paths)} images to process. Starting batch inference...\")\n",
    "    # --- Loop through images ---\n",
    "    for img_path in tqdm(image_paths, desc=\"Processing Images\"):\n",
    "        try:\n",
    "            # 1. Load Original Image\n",
    "            original_image_bgr = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "            if original_image_bgr is None: continue\n",
    "            original_image_rgb = cv2.cvtColor(original_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "            original_h, original_w = original_image_rgb.shape[:2]\n",
    "\n",
    "            # 2. Preprocess Image (consistent with training)\n",
    "            image_for_model = original_image_rgb.copy()\n",
    "\n",
    "            augmented = inference_augs_pipeline(image=image_for_model)\n",
    "            preprocessed = preprocessing_pipeline(image=augmented['image'])\n",
    "            input_tensor = preprocessed['image'].unsqueeze(0).to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "            # 3. Perform Inference\n",
    "            with torch.no_grad():\n",
    "                pred_output = inference_model(input_tensor)\n",
    "\n",
    "            # 4. Post-process Prediction\n",
    "            pred_probs = torch.sigmoid(pred_output) # Apply sigmoid to get probabilities\n",
    "            pred_prob_map = pred_probs.squeeze().cpu().numpy()\n",
    "            pred_mask_binary = (pred_prob_map > PREDICTION_THRESHOLD).astype(np.uint8)\n",
    "            pred_mask_resized = cv2.resize(pred_mask_binary, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # 5. Analyze Predicted Mask\n",
    "            output_cc = cv2.connectedComponentsWithStats(pred_mask_resized, 8, cv2.CV_32S)\n",
    "            num_labels = output_cc[0]\n",
    "            stats = output_cc[2]\n",
    "            centroids = output_cc[3]\n",
    "\n",
    "            for i in range(1, num_labels): # Skip background label 0\n",
    "                track_props = {\n",
    "                    \"image_filename\": os.path.basename(img_path), \"track_id\": i,\n",
    "                    \"area_px\": stats[i, cv2.CC_STAT_AREA],\n",
    "                    \"centroid_x_px\": round(centroids[i][0], 1), \"centroid_y_px\": round(centroids[i][1], 1),\n",
    "                }\n",
    "                if PIXEL_RESOLUTION_UM_PER_PX is not None:\n",
    "                    track_props[\"area_um2\"] = round(track_props[\"area_px\"] * (PIXEL_RESOLUTION_UM_PER_PX**2), 2)\n",
    "                all_detected_properties.append(track_props)\n",
    "\n",
    "            # Save a few samples for visualization at the end\n",
    "            if len(visualization_samples) < NUM_SAMPLES_TO_VISUALIZE:\n",
    "                visualization_samples.append({\n",
    "                    \"original\": original_image_rgb,\n",
    "                    \"predicted_mask\": pred_mask_resized,\n",
    "                    \"filename\": os.path.basename(img_path)\n",
    "                })\n",
    "\n",
    "        except Exception as e_loop:\n",
    "            print(f\"Error processing image {os.path.basename(img_path)}: {e_loop}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Batch inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "executionInfo": {
     "elapsed": 1161,
     "status": "ok",
     "timestamp": 1751532143888,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "SNrNmMn90trB",
    "outputId": "db419ca6-66b6-4e22-cf7c-c778f05dca6b"
   },
   "outputs": [],
   "source": [
    "if not all_detected_properties:\n",
    "  print(\"\\nNo tracks were detected in any of the processed images.\")\n",
    "else:\n",
    "    # --- Create and Display DataFrame ---\n",
    "  properties_df = pd.DataFrame(all_detected_properties)\n",
    "  print(f\"\\n--- Aggregated Results ---\")\n",
    "\n",
    "  print(f\"Total tracks found across all images: {len(properties_df)}\")\n",
    "  print(\"Sample of detected track properties:\")\n",
    "  display(properties_df.head())\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.hist(properties_df['area_px'], bins=50, edgecolor='black') # You can adjust the number of bins\n",
    "  plt.title('Distribution of Track Areas (in Pixels)')\n",
    "  plt.xlabel('Area (pixels)')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.grid(axis='y', alpha=0.75)\n",
    "  plt.show()\n",
    "\n",
    "  # --- Save to CSV ---\n",
    "  csv_output_path = os.path.join(OUTPUT_PATH, IMAGE_SPEC+\"_detected_track_properties.csv\")\n",
    "  properties_df.to_csv(csv_output_path, index=False)\n",
    "  print(f\"\\nFull results saved to: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1945,
     "status": "ok",
     "timestamp": 1751532175220,
     "user": {
      "displayName": "Claudio Galelli",
      "userId": "06065515014824448321"
     },
     "user_tz": -120
    },
    "id": "FwaDe2RB0wAL",
    "outputId": "5f421cc7-00ed-4bb5-9d74-9f20cf0dbca4"
   },
   "outputs": [],
   "source": [
    "if not visualization_samples:\n",
    "    print(\"\\nNo samples were saved for visualization.\")\n",
    "else:\n",
    "    print(\"\\n--- Example Visualizations with Overlays ---\")\n",
    "    for sample in visualization_samples:\n",
    "        original_img = sample[\"original\"]\n",
    "        pred_mask = sample[\"predicted_mask\"]\n",
    "        filename = sample[\"filename\"]\n",
    "\n",
    "        # Create overlay image\n",
    "        overlay = original_img.copy()\n",
    "        contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(overlay, contours, -1, (0, 255, 0), 1) # Draw contours in green\n",
    "\n",
    "        # Display the result\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(f\"Predicted Tracks on: {filename}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTa34RpLdykX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMsywhzgeEVgP9PYJ54Jbnh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "paleo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14c60120f92242fba7efec769301e649": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19708ff18d4545ef847724e9c41b0755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1dd3f54a68684034b5f11392c7751dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2337a372a3784adfa54f7e6af944b067": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e16b52f4a0d44a2bf5e69135bad222c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_faf451618b494071afbe46a198bca2de",
       "IPY_MODEL_9f7b1c43bdb44a65b0f7595dde324762",
       "IPY_MODEL_f711f124e1d54cc0981f0bf9f56b7a82"
      ],
      "layout": "IPY_MODEL_19708ff18d4545ef847724e9c41b0755"
     }
    },
    "3a3e3a9386bd42edbf95b56cd180ac39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42ed84645b494c939b264233f480776a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60edd04712624697b9de164c95120220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69310da730154458ad1197397d2589f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9908b8d198a44a809db7d44240af57d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f7b1c43bdb44a65b0f7595dde324762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2337a372a3784adfa54f7e6af944b067",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3ace6462d904ddab727fb976a0a2f3f",
      "value": 59
     }
    },
    "a4877cc62c3b40a9a69912ba239f1b7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0cc94574bc44acf91280adabdfae085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c23a9f66d68a41a28d1fcaee6e8baf7f",
       "IPY_MODEL_fcd950f2a5464b5092117e01c839a118",
       "IPY_MODEL_e13a8e6f94cc49b4a061ce3e0b4a5952"
      ],
      "layout": "IPY_MODEL_9908b8d198a44a809db7d44240af57d7"
     }
    },
    "c23a9f66d68a41a28d1fcaee6e8baf7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a3e3a9386bd42edbf95b56cd180ac39",
      "placeholder": "​",
      "style": "IPY_MODEL_f3bd213cbdaa4363a44a3fe8acd2a008",
      "value": "config.json: 100%"
     }
    },
    "c331c692b29c49db9f8f32c01030ff0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e13a8e6f94cc49b4a061ce3e0b4a5952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14c60120f92242fba7efec769301e649",
      "placeholder": "​",
      "style": "IPY_MODEL_ee127e37229c4c7386ede884d017759b",
      "value": " 156/156 [00:00&lt;00:00, 2.87kB/s]"
     }
    },
    "e3ace6462d904ddab727fb976a0a2f3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee127e37229c4c7386ede884d017759b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3bd213cbdaa4363a44a3fe8acd2a008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f711f124e1d54cc0981f0bf9f56b7a82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd3f54a68684034b5f11392c7751dd5",
      "placeholder": "​",
      "style": "IPY_MODEL_60edd04712624697b9de164c95120220",
      "value": " 59/59 [07:01&lt;00:00,  6.70s/it]"
     }
    },
    "faf451618b494071afbe46a198bca2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69310da730154458ad1197397d2589f8",
      "placeholder": "​",
      "style": "IPY_MODEL_a4877cc62c3b40a9a69912ba239f1b7f",
      "value": "Processing Images: 100%"
     }
    },
    "fcd950f2a5464b5092117e01c839a118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42ed84645b494c939b264233f480776a",
      "max": 156,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c331c692b29c49db9f8f32c01030ff0e",
      "value": 156
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
